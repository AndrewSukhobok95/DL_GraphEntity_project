{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"./../\"))\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Pretrained BERT\n",
    "\n",
    "### Documentation:\n",
    "\n",
    "- https://pypi.org/project/pytorch-pretrained-bert/\n",
    "- https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "\n",
    "### From documentation of pytorch-pretrained-bert\n",
    "\n",
    "This model outputs a tuple composed of:\n",
    "\n",
    "- `encoded_layers`: controled by the value of the output_encoded_layers argument:\n",
    "\n",
    "    - `output_all_encoded_layers=True`: outputs a list of the encoded-hidden-states at the end of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each encoded-hidden-state is a torch.FloatTensor of size **[batch_size, sequence_length, hidden_size]**,\n",
    "\n",
    "    - `output_all_encoded_layers=False`: outputs only the encoded-hidden-states corresponding to the last attention block, i.e. a single torch.FloatTensor of size **[batch_size, sequence_length, hidden_size]**,\n",
    "\n",
    "- `pooled_output`: a torch.FloatTensor of size **[batch_size, hidden_size]** which is the output of a classifier pretrained on top of the hidden state associated to the first character of the input (`CLF`) to train on the Next-Sentence task (see BERT's paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '[UNK]',\n",
       " 'want',\n",
       " 'to',\n",
       " 'ma',\n",
       " '##kir',\n",
       " '##ing',\n",
       " 'the',\n",
       " 'b',\n",
       " '##lo',\n",
       " '##ob',\n",
       " 'to',\n",
       " 'catch',\n",
       " 'good',\n",
       " 'bu',\n",
       " '##fc',\n",
       " '##art',\n",
       " '##ing',\n",
       " '##.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I want to makiring the bloob to catch good bufcarting.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "tokenizer.wordpiece_tokenizer.tokenize(marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"I want to makiring the bloob to catch good bufcarting.\"\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "tokenized_text = tokenizer.basic_tokenizer.tokenize(marked_text)\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, encoded_output = model(tokens_tensor, segments_tensors)\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.data_prep import EntityRelationsAligner, get_dataset\n",
    "from data_processing.BERTinizer import SentenceBERTinizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, ne_set, rel_set = get_dataset(\"./../data/preproc_NYT_json/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentenceBERTinizer()\n",
    "era = EntityRelationsAligner(tokenizer, list(ne_set), list(rel_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs0 = torch.tensor([[[1.,2.,3.]], [[4.,5.,6.]]])\n",
    "trs1 = torch.tensor([[[7.,8.,9.]], [[8.,6.,4.]]])\n",
    "\n",
    "trs0.size() # seq_len, batch, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs0 = trs0.view((trs0.shape[0], 1, trs0.shape[1], trs0.shape[2]))\n",
    "trs1 = trs1.view((1, trs1.shape[0], trs1.shape[1], trs1.shape[2]))\n",
    "\n",
    "trs0 = trs0.expand((trs0.shape[0], trs0.shape[0], trs0.shape[2], trs0.shape[3]))\n",
    "trs1 = trs1.expand((trs1.shape[1], trs1.shape[1], trs1.shape[2], trs1.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3.]],\n",
       "\n",
       "         [[1., 2., 3.]]],\n",
       "\n",
       "\n",
       "        [[[4., 5., 6.]],\n",
       "\n",
       "         [[4., 5., 6.]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7., 8., 9.]],\n",
       "\n",
       "         [[8., 6., 4.]]],\n",
       "\n",
       "\n",
       "        [[[7., 8., 9.]],\n",
       "\n",
       "         [[8., 6., 4.]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs = torch.cat([trs0, trs1], dim=3)\n",
    "trs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3., 7., 8., 9.]],\n",
       "\n",
       "         [[1., 2., 3., 8., 6., 4.]]],\n",
       "\n",
       "\n",
       "        [[[4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "         [[4., 5., 6., 8., 6., 4.]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3., 7., 8., 9.],\n",
       "          [1., 2., 3., 8., 6., 4.]],\n",
       "\n",
       "         [[4., 5., 6., 7., 8., 9.],\n",
       "          [4., 5., 6., 8., 6., 4.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs.permute(2, 0, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3., 7., 8., 9.],\n",
       "          [4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "         [[1., 2., 3., 8., 6., 4.],\n",
       "          [4., 5., 6., 8., 6., 4.]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs.permute(2, 0, 1, 3).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other data exploration (DRAFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"./data/re3d-master/Delegation of the European Union to Syria/documents.json\"\n",
    "ent_path = \"./data/re3d-master/Delegation of the European Union to Syria/entities.json\"\n",
    "rel_path = \"./data/re3d-master/Delegation of the European Union to Syria/relations.json\"\n",
    "\n",
    "with open(doc_path, \"r\", encoding=\"utf8\") as f:\n",
    "    doc_text = f.read()\n",
    "with open(ent_path, \"r\", encoding=\"utf8\") as f:\n",
    "    ent_text = f.read()\n",
    "with open(rel_path, \"r\", encoding=\"utf8\") as f:\n",
    "    rel_text = f.read()\n",
    "\n",
    "doc_text_list = doc_text.replace(\"}\\n{\", \"}###{\").split(\"###\")\n",
    "ent_text_list = ent_text.replace(\"}\\n{\", \"}###{\").split(\"###\")\n",
    "rel_text_list = rel_text.replace(\"}\\n{\", \"}###{\").split(\"###\")\n",
    "\n",
    "doc_json = [json.loads(e) for e in doc_text_list]\n",
    "ent_json = [json.loads(e) for e in ent_text_list]\n",
    "rel_json = [json.loads(e) for e in rel_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = doc_json[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '26E0189E3D774CB2B8F078A082E5088C-4-566-567-589-630-CommWith',\n",
       " 'begin': 1020,\n",
       " 'end': 1089,\n",
       " 'sourceBegin': 1018,\n",
       " 'sourceEnd': 1019,\n",
       " 'source': 'I',\n",
       " 'targetBegin': 1041,\n",
       " 'targetEnd': 1082,\n",
       " 'target': 'Turkish Foreign Minister Mevlüt Çavuşoğlu',\n",
       " 'type': 'CommWith',\n",
       " 'value': 'have spoken today to Turkish Foreign Minister Mevlüt Çavuşoğ lu and to',\n",
       " 'documentId': '26E0189E3D774CB2B8F078A082E5088C',\n",
       " 'confidence': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for r in rel_json:\n",
    "    l.append([r[\"source\"], r[\"target\"], r[\"type\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>Turkish Foreign Minister Mevlüt Çavuşoğlu</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>the UN Special Envoy Staffan de Mistura</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish Foreign Minister Mevlüt Çavuşoğlu</td>\n",
       "      <td>I</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the UN Special Envoy Staffan de Mistura</td>\n",
       "      <td>I</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>CoLocated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the EU</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>CoLocated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>over 9 billion euros</td>\n",
       "      <td>The EU</td>\n",
       "      <td>BelongsTo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Daesh</td>\n",
       "      <td>Syria</td>\n",
       "      <td>CoLocated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mogherini</td>\n",
       "      <td>EU leaders</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EU leaders</td>\n",
       "      <td>Mogherini</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>She</td>\n",
       "      <td>the Foreign Ministers of Iran, Saudi Arabia, E...</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the Foreign Ministers of Iran, Saudi Arabia, E...</td>\n",
       "      <td>She</td>\n",
       "      <td>CommWith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the UN Special Envoy de Mistura</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>CoLocated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                                                   I   \n",
       "1                                                   I   \n",
       "2           Turkish Foreign Minister Mevlüt Çavuşoğlu   \n",
       "3             the UN Special Envoy Staffan de Mistura   \n",
       "4                                                  We   \n",
       "5                                              the EU   \n",
       "6                                over 9 billion euros   \n",
       "7                                               Daesh   \n",
       "8                                           Mogherini   \n",
       "9                                          EU leaders   \n",
       "10                                                She   \n",
       "11  the Foreign Ministers of Iran, Saudi Arabia, E...   \n",
       "12                    the UN Special Envoy de Mistura   \n",
       "\n",
       "                                                    1          2  \n",
       "0           Turkish Foreign Minister Mevlüt Çavuşoğlu   CommWith  \n",
       "1             the UN Special Envoy Staffan de Mistura   CommWith  \n",
       "2                                                   I   CommWith  \n",
       "3                                                   I   CommWith  \n",
       "4                                            Brussels  CoLocated  \n",
       "5                                            Brussels  CoLocated  \n",
       "6                                              The EU  BelongsTo  \n",
       "7                                               Syria  CoLocated  \n",
       "8                                          EU leaders   CommWith  \n",
       "9                                           Mogherini   CommWith  \n",
       "10  the Foreign Ministers of Iran, Saudi Arabia, E...   CommWith  \n",
       "11                                                She   CommWith  \n",
       "12                                             Geneva  CoLocated  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
